{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "superpoint_handson.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOnljLtN3cActB6mjqNbEmY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Willyzw/SuperPointPretrainedNetwork/blob/master/superpoint_handson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw_SXI8fEA-H"
      },
      "source": [
        "# Superpoint Handson\n",
        "This demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn2EgPyhD96b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf1aef2f-da09-4926-e6d5-d8a42f2b0646"
      },
      "source": [
        "! git clone https://github.com/Willyzw/SuperPointPretrainedNetwork\n",
        "% cd /content/SuperPointPretrainedNetwork"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SuperPointPretrainedNetwork'...\n",
            "remote: Enumerating objects: 81, done.\u001b[K\n",
            "remote: Total 81 (delta 0), reused 0 (delta 0), pack-reused 81\u001b[K\n",
            "Unpacking objects: 100% (81/81), done.\n",
            "/content/SuperPointPretrainedNetwork\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_bFOgKEEROP"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "import PIL.Image as pil\n",
        "from IPython.display import Video\n",
        "from demo_superpoint import SuperPointFrontend, PointTracker, VideoStreamer, myjet"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlLAszKSEjXM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19b4e1e7-b513-4072-af40-6cb78e111767"
      },
      "source": [
        "# This class helps load input images from different sources.\n",
        "vs = VideoStreamer(\"assets/nyu_snippet.mp4\", camid=0, height=480, width=640, skip=1, img_glob='*.png')\n",
        "\n",
        "print('==> Loading pre-trained network.')\n",
        "# This class runs the SuperPoint network and processes its outputs.\n",
        "fe = SuperPointFrontend(weights_path='superpoint_v1.pth',\n",
        "                        nms_dist=4,\n",
        "                        conf_thresh=0.015,\n",
        "                        nn_thresh=0.7,\n",
        "                        cuda=False)\n",
        "print('==> Successfully loaded pre-trained network.')\n",
        "\n",
        "# This class helps merge consecutive point matches into tracks.\n",
        "tracker = PointTracker(5, nn_thresh=fe.nn_thresh)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Processing Video Input.\n==> Loading pre-trained network.\n==> Successfully loaded pre-trained network.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqpaHtf7EwSG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "00593b16-9eb4-43ad-90e8-62b39e3f49a3"
      },
      "source": [
        "vs.reset()\n",
        "print('==> Running Demo.')\n",
        "\n",
        "video = cv2.VideoWriter(\"demo.mp4\", cv2.VideoWriter_fourcc(*'XVID'), 3.0, (640*3,480))\n",
        "while True:\n",
        "  start = time.time()\n",
        "\n",
        "  # Get a new image.\n",
        "  img, status = vs.next_frame()\n",
        "  if status is False:\n",
        "    break\n",
        "\n",
        "  # Get points and descriptors.\n",
        "  start1 = time.time()\n",
        "  pts, desc, heatmap = fe.run(img)\n",
        "  end1 = time.time()\n",
        "\n",
        "  # Add points and descriptors to the tracker.\n",
        "  tracker.update(pts, desc)\n",
        "\n",
        "  # Get tracks for points which were match successfully across all frames.\n",
        "  tracks = tracker.get_tracks(2)\n",
        "\n",
        "  # Primary output - Show point tracks overlayed on top of input image.\n",
        "  out1 = (np.dstack((img, img, img)) * 255.).astype('uint8')\n",
        "  tracks[:, 1] /= float(fe.nn_thresh) # Normalize track scores to [0,1].\n",
        "  tracker.draw_tracks(out1, tracks)\n",
        "\n",
        "  # Extra output -- Show current point detections.\n",
        "  out2 = (np.dstack((img, img, img)) * 255.).astype('uint8')\n",
        "  for pt in pts.T:\n",
        "    pt1 = (int(round(pt[0])), int(round(pt[1])))\n",
        "    cv2.circle(out2, pt1, 1, (0, 255, 0), -1, lineType=16)\n",
        "  cv2.putText(out2, 'Raw Point Detections', (4, 12), cv2.FONT_HERSHEY_DUPLEX, 0.4, (255, 255, 255), lineType=16)\n",
        "\n",
        "  # Extra output -- Show the point confidence heatmap.\n",
        "  if heatmap is not None:\n",
        "    min_conf = 0.001\n",
        "    heatmap[heatmap < min_conf] = min_conf\n",
        "    heatmap = -np.log(heatmap)\n",
        "    heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + .00001)\n",
        "    out3 = myjet[np.round(np.clip(heatmap*10, 0, 9)).astype('int'), :]\n",
        "    out3 = (out3*255).astype('uint8')\n",
        "  else:\n",
        "    out3 = np.zeros_like(out2)\n",
        "  cv2.putText(out3, 'Raw Point Confidences', (4, 12), cv2.FONT_HERSHEY_DUPLEX, 0.4, (255, 255, 255), lineType=16)\n",
        "\n",
        "  # Compute runtime\n",
        "  end = time.time()\n",
        "  net_t = (1./ float(end1 - start))\n",
        "  total_t = (1./ float(end - start))\n",
        "\n",
        "  # Print and show result image\n",
        "  print('Processed image %d (net+post_process: %.2f FPS, total: %.2f FPS).'\\\n",
        "        % (vs.i, net_t, total_t))\n",
        "  out = np.hstack((out1, out2, out3))\n",
        "  video.write(out)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Running Demo.\n",
            "/home/wei/miniconda3/envs/nerfmm/lib/python3.8/site-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
            "Processed image 1 (net+post_process: 3.15 FPS, total: 3.06 FPS).\n",
            "Processed image 2 (net+post_process: 2.66 FPS, total: 2.41 FPS).\n",
            "Processed image 3 (net+post_process: 3.63 FPS, total: 3.15 FPS).\n",
            "Processed image 4 (net+post_process: 3.72 FPS, total: 3.22 FPS).\n",
            "Processed image 5 (net+post_process: 3.97 FPS, total: 3.36 FPS).\n",
            "Processed image 6 (net+post_process: 3.83 FPS, total: 3.28 FPS).\n",
            "Processed image 7 (net+post_process: 3.67 FPS, total: 3.16 FPS).\n",
            "Processed image 8 (net+post_process: 3.94 FPS, total: 3.36 FPS).\n",
            "Processed image 9 (net+post_process: 3.73 FPS, total: 3.19 FPS).\n",
            "Processed image 10 (net+post_process: 3.39 FPS, total: 2.94 FPS).\n",
            "Processed image 11 (net+post_process: 3.96 FPS, total: 3.37 FPS).\n",
            "Processed image 12 (net+post_process: 3.86 FPS, total: 3.29 FPS).\n",
            "Processed image 13 (net+post_process: 3.84 FPS, total: 3.29 FPS).\n",
            "Processed image 14 (net+post_process: 3.88 FPS, total: 3.30 FPS).\n",
            "Processed image 15 (net+post_process: 3.80 FPS, total: 3.26 FPS).\n",
            "Processed image 16 (net+post_process: 3.64 FPS, total: 3.13 FPS).\n",
            "Processed image 17 (net+post_process: 3.54 FPS, total: 3.05 FPS).\n",
            "Processed image 18 (net+post_process: 3.77 FPS, total: 3.21 FPS).\n",
            "Processed image 19 (net+post_process: 3.90 FPS, total: 3.29 FPS).\n",
            "Processed image 20 (net+post_process: 3.86 FPS, total: 3.27 FPS).\n",
            "Processed image 21 (net+post_process: 3.44 FPS, total: 2.96 FPS).\n",
            "Processed image 22 (net+post_process: 3.50 FPS, total: 3.02 FPS).\n",
            "Processed image 23 (net+post_process: 3.56 FPS, total: 3.08 FPS).\n",
            "Processed image 24 (net+post_process: 3.54 FPS, total: 3.06 FPS).\n",
            "Processed image 25 (net+post_process: 3.78 FPS, total: 3.22 FPS).\n",
            "Processed image 26 (net+post_process: 3.50 FPS, total: 3.02 FPS).\n",
            "Processed image 27 (net+post_process: 3.75 FPS, total: 3.19 FPS).\n",
            "Processed image 28 (net+post_process: 3.86 FPS, total: 3.27 FPS).\n",
            "Processed image 29 (net+post_process: 3.77 FPS, total: 3.19 FPS).\n",
            "Processed image 30 (net+post_process: 3.77 FPS, total: 3.19 FPS).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": "<video src=\"demo.mp4\" controls  >\n      Your browser does not support the <code>video</code> element.\n    </video>"
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "Video(\"demo.mp4\")"
      ]
    }
  ]
}